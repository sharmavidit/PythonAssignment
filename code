pip install beautifulsoup4

from bs4 import BeautifulSoup
import requests
import smtplib
import time
import datetime
from csv import writer
import pandas as pd
import re

#Part-1

amazon=[]
amazon1=[]
for i in range(1,21):
    URL=f"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_{i}"

    headers = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36" }

    page = requests.get(URL, headers=headers)

    soup1 = BeautifulSoup(page.content, "html.parser")

    soup2 = BeautifulSoup(soup1.prettify(), "html.parser")

    lists= soup2.find_all("div",class_="sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right")

    with open("amazonscrape.csv","w",encoding="utf8",newline="") as f:
        for list in lists:
          name=list.find("span",class_="a-size-medium a-color-base a-text-normal").text.strip().replace('\n','')
          rating=list.find("span",class_="a-icon-alt").text.strip().replace('\n','')
          urlitem=list.find("a",class_="a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal").attrs["href"].replace('\n','')
          reviews=list.find("span",class_="a-size-base s-underline-text").text.strip().replace('\n','')
          price=list.find("span",class_="a-price-whole").text.strip().replace('\n','')
          info=[name,rating,urlitem,reviews,price]
          amazon.append(info)
        
df=pd.DataFrame(amazon,columns=["Name","Rating","URL","Reviews","Price"])
df.to_csv("amazonscrape.csv")
